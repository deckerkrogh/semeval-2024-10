{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "9aAV2mXaZkjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NPDAx0YkTVgd"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "\n",
        "import gensim\n",
        "\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip /content/glove.6B.zip"
      ],
      "metadata": {
        "id": "Nbu_DK5qZwer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qpKDIttwZYCV"
      },
      "outputs": [],
      "source": [
        "path_to_glove_embedding = '/content/glove.6B.300d.txt'\n",
        "path_to_glove_embeddings_in_gensim_word2vec_format = './glove-word2vec.6B.300d.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uAXwErjZYCW",
        "outputId": "635f2ace-c851-40f8-a64f-6abaa38a0317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-403fd4d450d2>:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  _ = glove2word2vec(glove_file, tmp_file)\n"
          ]
        }
      ],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "glove_file = datapath(path_to_glove_embedding)\n",
        "tmp_file = get_tmpfile('./glove-word2vec.6B.300d.txt')\n",
        "_ = glove2word2vec(glove_file, tmp_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0XSLr3wFIW7",
        "outputId": "5aae026d-4a12-464f-a47e-95fd36356d89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQk2EHZbTO8G"
      },
      "outputs": [],
      "source": [
        "ptb = load_dataset('ptb_text_only')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"RNN and LSTM have to be used for Assignment 3\"\n",
        "# V = [10, 768] (context paragraph + question) C: NLP 243 is a class taught at UCSC. In NLP 243 we have to do assignmetns + final project + exams. Q: Where is the class taught?\n",
        "# K = [10, 100]\n",
        "# Q = [10, 100] (Answer) -> \"UCSC <PAD> <PAD>\"\n",
        "\n",
        "# softmax(K X Q^T) => [10, 10] x [10, 768] = [768, 10]\n",
        "\n",
        "# [\n",
        "#     1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 (RNN)\n",
        "#     0.99 0.01 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.01\n",
        "#     0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
        "#     0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
        "#     0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
        "#     0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
        "#     0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
        "# ]\n",
        "\n"
      ],
      "metadata": {
        "id": "7i6XyOz48gBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5tL9Zo4VYnm"
      },
      "outputs": [],
      "source": [
        "ptb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0SuxvWc-7GTd"
      },
      "outputs": [],
      "source": [
        "# train and validation sets\n",
        "\n",
        "train_data = [_text['sentence'] for _text in ptb['train']]\n",
        "val_data = [_text['sentence'] for _text in ptb['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2DcvxL9omTsZ"
      },
      "outputs": [],
      "source": [
        "# # Load glove6B embeddings into Gensim class containing matrix\n",
        "word2vec_weights = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gSbMKSH5oDAO"
      },
      "outputs": [],
      "source": [
        "# This is to encode the input text and pad it => encoded into list of indices\n",
        "class Sequencer(object):\n",
        "    def __init__(self, corpus, bos_token='<s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>'):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "\n",
        "        self.unk_index = self.add_token(unk_token)\n",
        "\n",
        "        self.pad_index = self.add_token(pad_token)\n",
        "\n",
        "        self.bos_index = self.add_token(bos_token)\n",
        "\n",
        "        self.eos_index = self.add_token(eos_token)\n",
        "\n",
        "        self.tokenizer = lambda text: [t for t in text.split(' ')]\n",
        "\n",
        "        for _sentence in corpus:\n",
        "            for _token in self.tokenizer(_sentence):\n",
        "                self.add_token(_token)\n",
        "\n",
        "    def add_token(self, token):\n",
        "\n",
        "        if token not in self.word2idx:\n",
        "            self.word2idx[token] = new_index = len(self.word2idx)\n",
        "            self.idx2word[new_index] = token\n",
        "            return new_index\n",
        "        else:\n",
        "            return self.word2idx[token]\n",
        "\n",
        "    def encode(self, text):\n",
        "\n",
        "        tokens = self.tokenizer(text)\n",
        "\n",
        "        sequence = []\n",
        "        sequence.append(self.bos_index)\n",
        "\n",
        "        for token in tokens:\n",
        "\n",
        "            index = self.word2idx.get(token, self.unk_index)\n",
        "            sequence.append(index)\n",
        "\n",
        "        sequence.append(self.eos_index)\n",
        "        return sequence\n",
        "\n",
        "    def create_padded_tensor(self, sequences):\n",
        "\n",
        "\n",
        "        lengths = [len(sequence) for sequence in sequences]\n",
        "        max_seq_len = max(lengths)\n",
        "        tensor = torch.full((len(sequences), max_seq_len), self.pad_index, dtype=torch.long)\n",
        "\n",
        "        for i, sequence in enumerate(sequences):\n",
        "            for j, token in enumerate(sequence):\n",
        "                tensor[i][j] = token\n",
        "\n",
        "        return tensor, torch.tensor(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y4ERHFHAlrzf"
      },
      "outputs": [],
      "source": [
        "# Maps text to index and then to corresponding embedding\n",
        "class PreTrainedSequencer(object):\n",
        "    def __init__(self, corpus, gensim_w2v, embedding_dim, bos_token='<s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>'):\n",
        "\n",
        "        self.idx2word = {}\n",
        "        self.word2idx = {}\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.w2v = gensim_w2v\n",
        "\n",
        "        self.w2v.add_vectors([bos_token], [np.random.uniform(low=-1, high=1.0, size=(self.embedding_dim,))])\n",
        "\n",
        "        self.w2v.add_vectors([eos_token], [np.random.uniform(low=-1, high=1.0, size=(self.embedding_dim,))])\n",
        "\n",
        "        self.w2v.add_vectors([unk_token], [np.random.uniform(low=-1, high=1.0, size=(self.embedding_dim,))])\n",
        "\n",
        "        self.w2v.add_vectors([pad_token], [np.random.uniform(low=-1, high=1.0, size=(self.embedding_dim,))])\n",
        "\n",
        "        self.bos_index = self.add_token(bos_token)\n",
        "\n",
        "        self.eos_index = self.add_token(eos_token)\n",
        "\n",
        "        self.unk_index = self.add_token(unk_token)\n",
        "\n",
        "        self.pad_index = self.add_token(pad_token)\n",
        "\n",
        "        self.tokenizer = lambda text: [t for t in text.split(' ')]\n",
        "\n",
        "        for _sentence in corpus:\n",
        "            for _token in self.tokenizer(_sentence):\n",
        "                self.add_token(_token)\n",
        "\n",
        "        self.pre_trained_embeddings = torch.zeros([len(self.idx2word.keys()), self.embedding_dim])\n",
        "\n",
        "        for idx, word in self.idx2word.items():\n",
        "            if self.w2v.has_index_for(word):\n",
        "                self.pre_trained_embeddings[idx] = torch.tensor(self.w2v.get_vector(self.w2v.key_to_index.get(word), norm=True))\n",
        "            else:\n",
        "\n",
        "                self.pre_trained_embeddings[idx] = torch.tensor(self.w2v.get_vector(self.w2v.key_to_index.get(unk_token), norm=True))\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token not in self.word2idx:\n",
        "            self.word2idx[token] = new_index = len(self.word2idx)\n",
        "            self.idx2word[new_index] = token\n",
        "            return new_index\n",
        "        else:\n",
        "            return self.word2idx[token]\n",
        "\n",
        "    def encode(self, text):\n",
        "\n",
        "\n",
        "        tokens = self.tokenizer(text)\n",
        "\n",
        "        sequence = []\n",
        "        sequence.append(self.bos_index)\n",
        "\n",
        "        for token in tokens:\n",
        "\n",
        "            index = self.word2idx.get(token, self.unk_index)\n",
        "            sequence.append(index)\n",
        "\n",
        "        sequence.append(self.eos_index)\n",
        "        return sequence\n",
        "\n",
        "    def create_padded_tensor(self, sequences):\n",
        "\n",
        "        lengths = [len(sequence) for sequence in sequences]\n",
        "        max_seq_len = max(lengths)\n",
        "        tensor = torch.full((len(sequences), max_seq_len), self.pad_index, dtype=torch.long)\n",
        "\n",
        "        for i, sequence in enumerate(sequences):\n",
        "            for j, token in enumerate(sequence):\n",
        "                tensor[i][j] = token\n",
        "\n",
        "        return tensor, lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2ac1a2MTmtbM"
      },
      "outputs": [],
      "source": [
        "# represent the penn treebank dataset, the _getitem converts a training example to embeddings along with output\n",
        "class PennTreebankDataset(Dataset):\n",
        "    def __init__(self, data, text_sequencer):\n",
        "\n",
        "        self.data = data\n",
        "        self.sequencer = text_sequencer\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_text = self.data[index]\n",
        "        x = self.sequencer.encode(input_text)\n",
        "        y = x[1:]\n",
        "        x = x[:-1]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "LciN6suLZYCY"
      },
      "outputs": [],
      "source": [
        "# RNN implementation\n",
        "class RNNLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, pad_index, embedding_dim, batch_size, hidden_size=100, bidirectional=False, num_layers=2, dropout_p=0.1, pre_trained_embeddings=None, tunable_pre_trained_embedding=False):\n",
        "        super(RNNLM, self).__init__()\n",
        "\n",
        "        self.pad_index = pad_index\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 1 if not self.bidirectional else 2\n",
        "\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "\n",
        "        self.dropout_p = dropout_p\n",
        "\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "        self.pre_trained_embeddings = pre_trained_embeddings\n",
        "\n",
        "        self.tunable_pre_trained_embedding = tunable_pre_trained_embedding if self.pre_trained_embeddings is not None else False\n",
        "\n",
        "        # add learnable embedding + frozen embedding or just frozen embedding\n",
        "        if self.pre_trained_embeddings is not None:\n",
        "\n",
        "            if self.tunable_pre_trained_embedding:\n",
        "                self.tunable_embedding = nn.Embedding.from_pretrained(self.pre_trained_embeddings, freeze=False)\n",
        "\n",
        "\n",
        "            self.embedding = nn.Embedding.from_pretrained(self.pre_trained_embeddings, freeze=True)\n",
        "        else:\n",
        "\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        embeddingSize = 2 if self.pre_trained_embeddings is not None and self.tunable_pre_trained_embedding else 1\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            bidirectional=self.bidirectional,\n",
        "            input_size=embeddingSize*self.embedding_dim, # tunable embedding.concat(frozen embedding)\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=self.num_layers,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(self.hidden_size*self.num_directions, self.embedding_dim, bias=False)\n",
        "\n",
        "        self.fc2 = nn.Linear(self.embedding_dim, self.vocab_size, bias=False)\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        h_0 = nn.Parameter(torch.randn(self.num_layers * self.num_directions, self.batch_size, self.hidden_size).type(torch.FloatTensor).to(device), requires_grad=True)\n",
        "        return h_0\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        h_0 = self.init_hidden()\n",
        "\n",
        "        if self.pre_trained_embeddings is not None:\n",
        "\n",
        "            embed_frozen = self.embedding(x)\n",
        "\n",
        "            if self.tunable_pre_trained_embedding:\n",
        "                embed_tunable = self.tunable_embedding(x)\n",
        "\n",
        "                embed = self.dropout(torch.cat((embed_tunable, embed_frozen), dim=2))\n",
        "\n",
        "            else:\n",
        "                embed = self.dropout(embed_frozen)\n",
        "        else:\n",
        "            embed = self.dropout(self.embedding(x))\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True, enforce_sorted=False) # batch_first -> (Input is B x T x *); enforce_sort -> sequences sorted by decreasing order\n",
        "\n",
        "        output, h_n = self.rnn(packed_input, h_0.detach())\n",
        "\n",
        "        seq_unpacked, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True, padding_value=self.pad_index) # pack the outputs to a padded matrix to feed to FFN\n",
        "\n",
        "        decoded = self.fc1(seq_unpacked)\n",
        "\n",
        "        decoded = self.dropout(decoded)\n",
        "\n",
        "        decoded = self.fc2(decoded)\n",
        "\n",
        "        logits = F.log_softmax(decoded, dim=-1) # get the highest prob to predict next word\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XJB0q65VgqbN"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "embedding_dim = 300\n",
        "batch_size = 16\n",
        "hidden_size=512\n",
        "bidirectional = False\n",
        "num_layers = 2\n",
        "dropout_p = 0.5\n",
        "tunable_pre_trained_embedding = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uVC1pSTZ-bys",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sequencer = Sequencer(train_data)\n",
        "pre_trained_embeddings = None\n",
        "vocab_size = len(sequencer.idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8IZwYr7wRVDv"
      },
      "outputs": [],
      "source": [
        "train_dataset = PennTreebankDataset(train_data, sequencer)\n",
        "val_dataset = PennTreebankDataset(val_data, sequencer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f-CqQjLdZYCa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_batch(batch, sequencer):\n",
        "    input_texts, output_texts = zip(*batch)\n",
        "    input_text_tensor, input_lengths = sequencer.create_padded_tensor(input_texts)\n",
        "    output_text_tensor, output_lengths = sequencer.create_padded_tensor(output_texts)\n",
        "    return (input_text_tensor, input_lengths, output_text_tensor)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, collate_fn=lambda batch: prepare_batch(batch, sequencer))\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda batch: prepare_batch(batch, sequencer), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XcuJy8GKZYCb"
      },
      "outputs": [],
      "source": [
        "model = RNNLM(vocab_size, sequencer.pad_index, embedding_dim=embedding_dim, batch_size=batch_size, hidden_size=hidden_size, bidirectional=bidirectional, num_layers=num_layers, dropout_p=dropout_p, tie_weights=tie_weights, pre_trained_embeddings=pre_trained_embeddings, tunable_pre_trained_embedding=tunable_pre_trained_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nezdv9Cg34F",
        "outputId": "71758cb4-72c4-4925-8135-00f5ce4260a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLM(\n",
              "  (embedding): Embedding(10002, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (rnn): RNN(300, 512, num_layers=2, bias=False)\n",
              "  (fc1): Linear(in_features=512, out_features=300, bias=False)\n",
              "  (fc2): Linear(in_features=300, out_features=10002, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P1jnrzpKhkME"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0005\n",
        "\n",
        "loss_function = nn.NLLLoss(ignore_index=sequencer.pad_index) # negative log likelihood loss\n",
        "# Perplexity = 2^-log likelihood\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rqOmlD9TZYCc"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loss_function, loader, device):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.\n",
        "\n",
        "        running_loss_history = []\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            batch_size = batch[0].shape[0]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(batch[0].to(device), batch[1])\n",
        "\n",
        "            loss = loss_function(pred.view(-1, pred.size(2)), batch[2].view(-1).to(device))\n",
        "\n",
        "            running_loss += (loss.item() - running_loss) / (i + 1)\n",
        "            running_loss_history.append(running_loss)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            predictions = torch.argmax(pred, dim=-1)\n",
        "\n",
        "        mean_running_loss = np.mean(running_loss_history)\n",
        "\n",
        "        del running_loss_history\n",
        "\n",
        "        return mean_running_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nEVVM1KDiLfZ"
      },
      "outputs": [],
      "source": [
        "def run_training(model, optimizer, loss_function, train_loader, valid_loader, device, n_epochs=20):\n",
        "        train_running_losses = []\n",
        "\n",
        "        min_loss = 1000\n",
        "\n",
        "        for i in range(n_epochs):\n",
        "            print(f\"Epoch: {i}\")\n",
        "\n",
        "\n",
        "            train_running_loss_history = train(model, optimizer, loss_function, train_loader, device)\n",
        "\n",
        "\n",
        "            train_running_losses.append(train_running_loss_history)\n",
        "\n",
        "        all_train_running_losses = list(chain.from_iterable(train_running_losses))\n",
        "        all_train_running_perplexity = list(chain.from_iterable(train_running_perplexity))\n",
        "\n",
        "\n",
        "        train_epoch_idx = range(len(all_train_running_losses))\n",
        "\n",
        "        train_epoch_idx = range(len(all_train_running_perplexity))\n",
        "\n",
        "\n",
        "        return all_train_running_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xKrb4W8aZYCc"
      },
      "outputs": [],
      "source": [
        "# clear gpu cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "m5pZl1X9ZYCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "be75d89f-05aa-4126-8a41-301cb389496f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-907aef6447de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-554de1afac01>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, loss_function, train_loader, valid_loader, device, n_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtrain_running_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-13d7b13922a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_function, loader, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7185468aac23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mseq_unpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_TANH'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 result = _VF.rnn_tanh(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    563\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                                       self.bidirectional)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_loss = run_training(model, optimizer, loss_function, train_loader, val_loader, device, n_epochs=30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}